{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eab1511-2a3f-459a-844c-83988b40085e",
   "metadata": {},
   "source": [
    "Импортируем все необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e55edf49-9f6c-4fac-aa43-dbb35be81d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\anaconda\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: natasha in c:\\anaconda\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: click in c:\\anaconda\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\anaconda\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\anaconda\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: pymorphy2 in c:\\anaconda\\lib\\site-packages (from natasha) (0.9.1)\n",
      "Requirement already satisfied: razdel>=0.5.0 in c:\\anaconda\\lib\\site-packages (from natasha) (0.5.0)\n",
      "Requirement already satisfied: navec>=0.9.0 in c:\\anaconda\\lib\\site-packages (from natasha) (0.10.0)\n",
      "Requirement already satisfied: slovnet>=0.6.0 in c:\\anaconda\\lib\\site-packages (from natasha) (0.6.0)\n",
      "Requirement already satisfied: yargy>=0.16.0 in c:\\anaconda\\lib\\site-packages (from natasha) (0.16.0)\n",
      "Requirement already satisfied: ipymarkup>=0.8.0 in c:\\anaconda\\lib\\site-packages (from natasha) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: intervaltree>=3 in c:\\anaconda\\lib\\site-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\anaconda\\lib\\site-packages (from pymorphy2->natasha) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\anaconda\\lib\\site-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\anaconda\\lib\\site-packages (from pymorphy2->natasha) (0.6.2)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in c:\\anaconda\\lib\\site-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk natasha scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "af037750-552c-4022-85d0-bee7a8f7a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import math\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import pymorphy2\n",
    "\n",
    "from natasha import Doc, Segmenter, MorphVocab, NewsEmbedding, NewsMorphTagger\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "f6af678e-0991-4b56-8a73-8f88540705ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Пользователь\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf08964f-e360-45ba-b00c-e94a2827b790",
   "metadata": {},
   "source": [
    "Выделение обозначения стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "fe8b5aef-6a41-4127-ae49-0668ed4ec527",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "d57af867-508b-4adc-8f31-1554d072b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Мама мыла раму и пела песню.\",\n",
    "    \"Сегодня прекрасная погода, и мы пошли гулять в парк.\",\n",
    "    \"Студенты изучают программирование на Python и создают интересные проекты.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a30a42-f967-4224-8d3f-0c3519fc1cc3",
   "metadata": {},
   "source": [
    "Функция лемматизации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "121446cc-bf55-486b-b6d9-6d9f4aaabf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm(text):\n",
    "    \n",
    "    segmenter = Segmenter()\n",
    "    Vocab = MorphVocab()\n",
    "    Embeddings = NewsEmbedding()\n",
    "    Tagger = NewsMorphTagger(Embeddings)\n",
    "    Stemmer = SnowballStemmer(\"russian\")\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(Tagger)\n",
    "    \n",
    "    lems = []\n",
    "    for token in doc.tokens:\n",
    "        if token.lemma and token.lemma.isalnum():  \n",
    "            lems.append(token.lemma)\n",
    "        else:\n",
    "            parsed = morph.parse(token.text)[0]\n",
    "            if parsed.normal_form.isalnum():\n",
    "                lems.append(parsed.normal_form)\n",
    "    \n",
    "    return lems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48547e-6af2-4472-9ad6-91ae9ded7819",
   "metadata": {},
   "source": [
    "Функция токенизации текста(без стоп-слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "ab9ce606-96f6-44af-b9ab-20da2c77f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53edd50d-2269-4d16-bc08-d03438f3572b",
   "metadata": {},
   "source": [
    "Функция удаления стоп-слов(по аналогии с токенизацией, но отдельная функция):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "6f68074a-8bab-4690-ae77-4724271a055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(texts):\n",
    "    def clean_sentence(sentence):\n",
    "        tokens = word_tokenize(sentence.lower())\n",
    "        tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "        return tokens\n",
    "    \n",
    "    if isinstance(texts, list):  \n",
    "        if all(isinstance(item, str) for item in texts):  \n",
    "            return [clean_sentence(sentence) for sentence in texts]\n",
    "        elif all(isinstance(item, list) for item in texts):  \n",
    "            return [[word for word in sentence if word not in stop_words] for sentence in texts]\n",
    "    \n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb39de-fe7a-401b-8a84-79a9c123633d",
   "metadata": {},
   "source": [
    "исполнение всех функций блоками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "964ac7d7-34f3-441a-9559-d78172969866",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tokenize_text(text) for text in texts] #токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "98645e94-de71-41ef-a6b6-1b1cb4f84d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemms = [lemm(text) for text in texts] #Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "1a0d1d45-980f-4d00-85bf-e45d2f620ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = remove_stop_words(texts) #удаление стоп слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783dbab2-86b7-4156-b914-9aeb293a1699",
   "metadata": {},
   "source": [
    "Вывод результатов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "b63024d4-b9ed-4407-8192-fa728fba19c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты токенизации(без удаления стоп-слов):\n",
      "[['мама', 'мыла', 'раму', 'и', 'пела', 'песню'], ['сегодня', 'прекрасная', 'погода', 'и', 'мы', 'пошли', 'гулять', 'в', 'парк'], ['студенты', 'изучают', 'программирование', 'на', 'python', 'и', 'создают', 'интересные', 'проекты']]\n",
      "Результаты удаления стоп-слов в исходном тексте:\n",
      "[['мама', 'мыла', 'раму', 'пела', 'песню'], ['сегодня', 'прекрасная', 'погода', 'пошли', 'гулять', 'парк'], ['студенты', 'изучают', 'программирование', 'python', 'создают', 'интересные', 'проекты']]\n",
      "Результаты ламматизации:\n",
      "[['мама', 'мыло', 'рама', 'и', 'петь', 'песня'], ['сегодня', 'прекрасный', 'погода', 'и', 'мы', 'послать', 'гулять', 'в', 'парк'], ['студент', 'изучать', 'программирование', 'на', 'python', 'и', 'создавать', 'интересный', 'проект']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Результаты токенизации(без удаления стоп-слов):\")\n",
    "print(tokens)\n",
    "\n",
    "print(\"Результаты удаления стоп-слов в исходном тексте:\")\n",
    "print(stopwords)\n",
    "\n",
    "print(\"Результаты ламматизации:\")\n",
    "print(lemms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708267ef-7e7e-4140-aa35-a0cdcff3b64d",
   "metadata": {},
   "source": [
    "Создаем список уникальных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "40d29f23-ab75-4313-9a68-4ea01edea5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(tokenized_texts):\n",
    "    vocab = set()\n",
    "    for tokens in tokenized_texts:\n",
    "        vocab.update(tokens)\n",
    "    return sorted(vocab) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88dba8-b5b3-4b7c-8716-34cf6f26b5a7",
   "metadata": {},
   "source": [
    "Строим матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "62f3d838-45db-4a29-b055-04d6c8deee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_texts):\n",
    "    vocab = build_vocab(tokenized_texts)\n",
    "    word_to_index = {word: i for i, word in enumerate(vocab)}  # Индексы слов\n",
    "    \n",
    "    matrix = []\n",
    "    for tokens in tokenized_texts:\n",
    "        row = [0] * len(vocab)\n",
    "        for token in tokens:\n",
    "            if token in word_to_index:\n",
    "                row[word_to_index[token]] += 1  # Увеличиваем счётчик слова\n",
    "        matrix.append(row)\n",
    "    \n",
    "    return vocab, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "75be45ed-6c0d-4a1e-9f62-ecab79749a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_features, bow_matrix = bag_of_words(stopwords)\n",
    "\n",
    "#красивый вывод на табличке\n",
    "bow_df = pd.DataFrame(bow_matrix, columns=bow_features)\n",
    "bow_df.index = [f\"Предложение {i+1}\" for i in range(len(texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "8eb4e7b3-9538-4d73-839b-ee7937e61aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>python</th>\n",
       "      <th>гулять</th>\n",
       "      <th>изучают</th>\n",
       "      <th>интересные</th>\n",
       "      <th>мама</th>\n",
       "      <th>мыла</th>\n",
       "      <th>парк</th>\n",
       "      <th>пела</th>\n",
       "      <th>песню</th>\n",
       "      <th>погода</th>\n",
       "      <th>пошли</th>\n",
       "      <th>прекрасная</th>\n",
       "      <th>программирование</th>\n",
       "      <th>проекты</th>\n",
       "      <th>раму</th>\n",
       "      <th>сегодня</th>\n",
       "      <th>создают</th>\n",
       "      <th>студенты</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Предложение 1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Предложение 2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Предложение 3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               python  гулять  изучают  интересные  мама  мыла  парк  пела  \\\n",
       "Предложение 1       0       0        0           0     1     1     0     1   \n",
       "Предложение 2       0       1        0           0     0     0     1     0   \n",
       "Предложение 3       1       0        1           1     0     0     0     0   \n",
       "\n",
       "               песню  погода  пошли  прекрасная  программирование  проекты  \\\n",
       "Предложение 1      1       0      0           0                 0        0   \n",
       "Предложение 2      0       1      1           1                 0        0   \n",
       "Предложение 3      0       0      0           0                 1        1   \n",
       "\n",
       "               раму  сегодня  создают  студенты  \n",
       "Предложение 1     1        0        0         0  \n",
       "Предложение 2     0        1        0         0  \n",
       "Предложение 3     0        0        1         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Bag of Words:\")\n",
    "display(bow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f540c5-276a-4961-9da0-1ad2b5cda9a2",
   "metadata": {},
   "source": [
    "Вычисляет TF (Term Frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "2b19e57c-35a7-4731-902c-436c27331775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(tokens, vocab):\n",
    "    word_count = len(tokens)\n",
    "    tf = {word: tokens.count(word) / word_count for word in vocab}  # Частота слова в документе\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f225363-bc4e-4bac-8336-a4bbb7d133f7",
   "metadata": {},
   "source": [
    "Вычисляет IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "50a3ea9d-90e4-4b85-929a-469868ce1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(tokenized_texts, vocab):\n",
    "    num_docs = len(tokenized_texts)\n",
    "    idf = {}\n",
    "    for word in vocab:\n",
    "        doc_count = sum(1 for tokens in tokenized_texts if word in tokens)  # В скольких документах встречается\n",
    "        idf[word] = math.log((num_docs + 1) / (doc_count + 1)) + 1  # Формула с добавлением 1\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a161f83d-25cf-4c02-a58a-44b45388eba6",
   "metadata": {},
   "source": [
    "Строит матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "968d61f1-16cc-42b9-a2f3-6ab258c424fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(tokenized_texts):\n",
    "    vocab = build_vocab(tokenized_texts)\n",
    "    idf = compute_idf(tokenized_texts, vocab)\n",
    "    \n",
    "    tf_idf_matrix = []\n",
    "    for tokens in tokenized_texts:\n",
    "        tf = compute_tf(tokens, vocab)\n",
    "        tf_idf_vector = [tf[word] * idf[word] for word in vocab]  # TF * IDF\n",
    "        tf_idf_matrix.append(tf_idf_vector)\n",
    "    \n",
    "    return vocab, tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "064ffd9d-6265-4f31-9762-bbd234a0085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_features, tfidf_matrix = tf_idf(stopwords)\n",
    "\n",
    "#красивый вывод на табличке\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix, columns=tfidf_features)\n",
    "tfidf_df.index = [f\"Предложение {i+1}\" for i in range(len(texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "8d25a9b2-0ce5-4274-9a06-0764b5b127da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>python</th>\n",
       "      <th>гулять</th>\n",
       "      <th>изучают</th>\n",
       "      <th>интересные</th>\n",
       "      <th>мама</th>\n",
       "      <th>мыла</th>\n",
       "      <th>парк</th>\n",
       "      <th>пела</th>\n",
       "      <th>песню</th>\n",
       "      <th>погода</th>\n",
       "      <th>пошли</th>\n",
       "      <th>прекрасная</th>\n",
       "      <th>программирование</th>\n",
       "      <th>проекты</th>\n",
       "      <th>раму</th>\n",
       "      <th>сегодня</th>\n",
       "      <th>создают</th>\n",
       "      <th>студенты</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Предложение 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338629</td>\n",
       "      <td>0.338629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338629</td>\n",
       "      <td>0.338629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Предложение 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Предложение 3</th>\n",
       "      <td>0.241878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241878</td>\n",
       "      <td>0.241878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241878</td>\n",
       "      <td>0.241878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241878</td>\n",
       "      <td>0.241878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 python    гулять   изучают  интересные      мама      мыла  \\\n",
       "Предложение 1  0.000000  0.000000  0.000000    0.000000  0.338629  0.338629   \n",
       "Предложение 2  0.000000  0.282191  0.000000    0.000000  0.000000  0.000000   \n",
       "Предложение 3  0.241878  0.000000  0.241878    0.241878  0.000000  0.000000   \n",
       "\n",
       "                   парк      пела     песню    погода     пошли  прекрасная  \\\n",
       "Предложение 1  0.000000  0.338629  0.338629  0.000000  0.000000    0.000000   \n",
       "Предложение 2  0.282191  0.000000  0.000000  0.282191  0.282191    0.282191   \n",
       "Предложение 3  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "\n",
       "               программирование   проекты      раму   сегодня   создают  \\\n",
       "Предложение 1          0.000000  0.000000  0.338629  0.000000  0.000000   \n",
       "Предложение 2          0.000000  0.000000  0.000000  0.282191  0.000000   \n",
       "Предложение 3          0.241878  0.241878  0.000000  0.000000  0.241878   \n",
       "\n",
       "               студенты  \n",
       "Предложение 1  0.000000  \n",
       "Предложение 2  0.000000  \n",
       "Предложение 3  0.241878  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nTF-IDF:\")\n",
    "display(tfidf_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
